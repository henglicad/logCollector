###
### Producer Basics
###

#The id string to pass to the server when making requests. The purpose of this is to be able to track the source of 
#requests beyond just ip/port by allowing a logical application name to be included with the request. 
#The application can set any string it wants as this has no functional purpose other than in logging and metrics.
#
client.id=log-producer

# A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. 
# Data will be load balanced over all servers irrespective of which servers are specified here for
# bootstrapping - this list only impacts the initial hosts used to discover the full set of servers. 
#
# This list should be in the form:
#	 host1:port1,host2:port2,.... 
#
# Since these servers are just used for the initial connection to discover the full cluster membership 
# (which may change dynamically), this list need not contain the full set of servers (you may want more 
# than one, though, in case a server is down). If no server in this list is available sending data will fail until 
# on becomes available.
#
#bootstrap.servers=localhost:9092





# The partitioner class for partitioning messages amongst sub-topics. The default partitioner is based on the hash of
# the key.
#
#partitioner.class=kafka.producer.DefaultPartitioner



# The number of acknowledgments the producer requires the leader to have received before considering a request complete. 
# This controls the durability of records that are sent. The following settings are common:
#
# acks=0 If set to zero then the producer will not wait for any acknowledgment from the server 
# at all. The record will be immediately added to the socket buffer and considered sent. 
# No guarantee can be made that the server has received the record in this case, 
# and the retries configuration will not take effect (as the client won't generally know of 
# any failures). The offset given back for each record will always be set to -1.
#
# acks=1 This will mean the leader will write the record to its local log but will respond 
# without awaiting full acknowledgement from all followers. In this case should the leader fail 
# immediately after acknowledging the record but before the followers have replicated it then the 
# record will be lost.
# 
# acks=all This means the leader will wait for the full set of in-sync replicas to acknowledge 
# the record. This guarantees that the record will not be lost as long as at least one in-sync 
# replica remains alive. This is the strongest available guarantee.
#
# Other settings such as acks=2 are also possible, and will require the given number of 
# acknowledgements but this is generally less useful.
#
#acks=1


# The producer will attempt to batch records together into fewer requests whenever multiple records
# are being sent to the same partition. This helps performance on both the client and the server. 
# This configuration controls the default batch size in bytes.
#
# No attempt will be made to batch records larger than this size.
#
# Requests sent to brokers will contain multiple batches, one for each partition with data 
# available to be sent.
#
# A small batch size will make batching less common and may reduce throughput (a batch size 
# of zero will disable batching entirely). A very large batch size may use memory a bit more 
# wastefully as we will always allocate a buffer of the specified batch size in anticipation 
# of additional records.
#
#batch.size=16384

# The compression type for all data generated by the producer. The default is none 
# (i.e. no compression). Valid values are none, gzip, or snappy. Compression is of full batches 
# of data, so the efficacy of batching will also impact the compression ratio 
# (more batching means better compression).
#
#compression.type=snappy

#The serializer class for keys (defaults to the same as for messages if nothing is given).
#
#key.serializer=org.apache.kafka.common.serialization.StringSerializer
#value.serializer=org.apache.kafka.common.serialization.StringSerializer




########################################## 0.8.1.1 ##########################################
serializer.class=kafka.serializer.StringEncoder
#This is for bootstrapping and the producer will only use it for getting metadata (topics, partitions and replicas). 
# The socket connections for sending the actual data will be established based on the broker information returned in 
# the metadata. The format is host1:port1,host2:port2, and the list can be a subset of brokers or a VIP pointing to a 
# subset of brokers.
#
metadata.broker.list=localhost:9092

# specifies whether the messages are sent asynchronously (async) or synchronously (sync)
# Specifies whether the messages are sent asynchronously in a background thread.  Valid values are (1) "async" for
# asynchronous send and (2) "sync" for synchronous send.  By setting the producer to async we allow batching together of
# requests (which is great for throughput) but open the possibility of a failure of the client machine dropping unsent
# data.
#
producer.type=async

request.required.acks=1

# https://issues.apache.org/jira/browse/KAFKA-1494
##retry.backoff.ms=1000
#topic.metadata.refresh.interval.ms=0
#message.send.max.retries=10
